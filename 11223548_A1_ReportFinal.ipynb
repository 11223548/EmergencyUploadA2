{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "11223548_A1_ReportFinal.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/11223548/UTS_ML2019_Main/blob/master/11223548_A1_ReportFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4vXJOARx1KC",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on Generative Adversarial Nets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu1ZQBe9ym_L",
        "colab_type": "text"
      },
      "source": [
        "**Student ID:** 11223548\n",
        "<br>**GitHub Link:**\n",
        "<br>https://colab.research.google.com/drive/11k2W1qBchTqtBbBCNrovV-GzN4E8mc7R#scrollTo=c4rrqacwx1KI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA1LVL1Tx1KG",
        "colab_type": "text"
      },
      "source": [
        "## Introduction & Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9kefFdIx1KH",
        "colab_type": "text"
      },
      "source": [
        "<justify>“*Generative Adversarial Nets*” (Goodfellow et al., 2014) was a seminal paper in unsupervised machine learning which introduced a new framework for generating synthetic observations that are indistinguishable from real training data observations. The framework introduced by Goodfellow et al. aims to overcome some of the significant challenges faced by various pre-existing generative models. In particular, the adversarial framework proposed by the authors averts the need for Markov chains (which carry high computational costs), averts the requirement for inferences during learning and uses a generator function that is capable of incorporating a wider variety of functions than prior methods.\n",
        "\n",
        "<br>Generative adversarial networks (**GAN**) involve a training process whereby two “adversarial” machine learning models, typically neural networks, compete in a “game” that causes each model to be refined over time. A generative model is fed noise (which represents the latent features of an observation to be generated) and attempts to generate synthetic observations that closely resemble training data. A discriminative model then attempts to distinguish observations that are genuine vs. synthetic (produced by the generative model). The generative model attempts to minimise the probability of producing an observation that the discriminative model will classify as synthetic whilst the discriminative model attempts to maximise the probability of accurately classifying synthetic and genuine samples.\n",
        "\n",
        "<br>As formalised by Goodfellow et al., the generative model (**G**) and discriminative model (**D**) are “playing” a two-player minimax game with value function V(G,D):</justify>\n",
        "\n",
        "\n",
        "<br><center><img src=\"https://github.com/11223548/UTS_ML2019_Main/blob/master/GAN_Equation.jpg?raw=true\" width=\"800\"/></center>\n",
        "\n",
        "<br><justify>Both models are retrained (backpropagated) on an alternating basis so that the generative model produces better synthetic observations (aligned with the underlying data distribution), while the discriminative model becomes more proficient at flagging synthetic observations. Completely optimising the discriminative model after every iteration of generative model optimisation would be computationally prohibitive and induce model overfitting. As a result, the authors instead propose a ‘*k*’ steps limit on the optimisation of the discriminative model for each loop. Eventually the GAN will reach a Nash Equilibrium with neither the generative model nor discriminative model able to make further unilateral improvements. Goodfellow et al. derive the optimal value of D for the minimax game presented above and show that the probability distribution of the generative model converges to the probability distribution of the training data. \n",
        "\n",
        "<br>The framework introduced by Goodfellow et al. was applied within the context of multilayer perceptron models due to the simplicity of implementation for this model specification. However, the principles developed by Goodfellow et al. have since been extended and implemented for other forms of machine learning models such as deep convolutional GANs, CycleGAN, StackGAN, DiscoGAN, etc. In the relatively short period of time since the paper was disseminated, research into the application and extensions of generative adversarial networks has become a burgeoning field within unsupervised machine learning.</justify>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4rrqacwx1KI",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxlfYupzx1KK",
        "colab_type": "text"
      },
      "source": [
        "<justify>Various forms of generative models existed prior to the paper by Goodfellow et al. The creative innovation introduced by GANs is the introduction of a methodology whereby a separate adversarial network is used to help train the generative model. Prior to this innovation, deep generative models had experienced significant difficulty in approximating intractable probabilistic computations that arose in the estimation strategies commonly deployed in predecessor generative models. Markov Chain Monte Carlo (**MCMC**) methods were commonly used to approximate probability distributions. However, MCMC approaches carried high computational costs and encountered difficulties when working with sharp distributions. GANs managed to provide an alternate estimation approach that averted the need for such intractable probabilistic computations by alternatively targeting synchronisation between the generative and discriminative models (i.e. the adversarial system). Furthermore, the GAN innovation carried the additional benefits of not requiring inference during learning and the ability to handle practically any differentiable function. This differs from some predecessor generative approaches which could only function with a comparatively more limited subset of data distributions.\n",
        "\n",
        "<br>The table below is an excerpt from page 7 of the Goodfellow et al. paper that further contrasts how the proposed adversarial model deals with challenges in generative modelling compared to other existing generative models.</justify>\n",
        "\n",
        "<br><center>**Generative Model Comparison**\n",
        "<br><img src=\"https://github.com/11223548/UTS_ML2019_Main/blob/master/GAN-GenerativeChallengesComp.JPG?raw=true\" width=\"800\"/>\n",
        "<br>Source: Generative Adversarial Nets, 2014</center>\n",
        "\n",
        "<br><justify>When considering the innovation of the paper, it is important to recognise that GANs, as introduced by Goodfellow et al., represent a framework rather than specific machine learning model. The framework itself is far more innovative than the multilayer perceptron model presented in the paper (which was only one example of a specific implementation). The framework provided an intuitive means for subsequent researchers and practitioners to conceptualise and develop a wide variety of specific models and implementations. To highlight just how influential the GAN framework has been, consider that although the Goodfellow et al. paper was only published in 2014 there have already been thousands of subsequent GAN research papers produced [Ref.7]. GANs have also garnered a strong adoption outside of academia due to the large number of potential use cases.</justify>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF6mfjssx1KL",
        "colab_type": "text"
      },
      "source": [
        "## Technical Quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OE2M6cvx1KM",
        "colab_type": "text"
      },
      "source": [
        "<justify>The paper is of a high technical quality with theoretical results and experimental results used to support the claims of the authors. The technical developments presented in the paper are relatively simple yet profound. The rationale for an adversarial system seems intuitive when explained by the authors. The authors explain the challenges faced by existing generative approaches and how a GAN framework averts many of the significant challenges faced by alternate generative models. At this point it becomes clear that although implementation of a GAN may be relatively simple, the framework resolves many highly sophisticated technical issues associated with generative modelling (as discussed in the preceding section of this report). \n",
        "\n",
        "<br>Goodfellow et al. derive the optimal theoretical value of different parameters within the proposed GAN framework. They find that at the global optimum, the generative model’s probability distribution will be equivalent to the probability distribution of the training data. This is an important theoretical result since it shows that the synthetic observations produced should eventually become indistinguishable from the real training observations. In addition, the authors provide a theoretical basis as to why the generative model converges towards producing observations that reflect a probability distribution equivalent to the probability distribution of the training data. This suggests that not only does a global optimum exist within a GAN framework, but that the generative model will also converge to this global optimum. However, it is worth noting that this proof requires the caveat that incremental updates to the generative model are sufficiently small. The derivation for the optimal discriminator has withstood academic scrutiny thus far and remains a proof which is frequently relied upon in more recent GAN papers [Ref.10].\n",
        "\n",
        "<br>Whilst an overall impressive paper, the GAN approach presented by Goodfellow et al. does suffer from some weaknesses. The generative model prescribed can encounter significant difficulty in initial training due to the discriminative model being able to reject synthetic observations with high confidence. This creates a very limited pool of successful counterfeits to enable backpropagation of the generative network and can stall generative model training improvements. Furthermore, GANs are vulnerable to mode collapse; if the generative model is overfitted in-between iterations of training the discriminative model then the generative model will begin to generate multiple copies of the exact same synthetic observation.\n",
        "\n",
        "<br>Another weakness which is specific to the paper, rather than the GAN framework, is that Goodfellow et al. presented only one very limited table quantifying the performance of a GAN vs. pre-existing models. The experimental results section of the paper is noticeably less convincing then earlier sections of the paper. In particular, since the authors argue that there are significant computational advantages that arise from using GAN it would have been appropriate to quantify this advantage to some extent. The enthusiastic adoption of GANs following the publishing of the paper suggest that the authors claims regarding superiority of GANs over alternate generative models are valid. However, based on the limited tangible evidence of outperformance in the paper it would have been difficult to anticipate that GANs represented such a momentous innovation.</justify>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QbL2PbJx1KO",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nt41wAtx1KQ",
        "colab_type": "text"
      },
      "source": [
        "<center>“the coolest idea in machine learning in the last twenty years”\n",
        "<br> - Yann LeCun, the Chief AI Scientist at Facebook, describing his view on GANs</center>\n",
        "\n",
        "<br><justify>GANs have sparked a lot of excitement for machine learning researchers and practitioners due to their huge array of potential applications in the real world. In particular, GANs have a very broad application to a domain of problems that traditional machine learning models found challenging. Traditional machine learning methods have excelled at identification and classification tasks whilst the functionality of generative methods have lagged behind. With the introduction of GANs it has become much easier to generate realistic datasets that mirror real world observations. For example, GANs excel at replicating creative tasks such as generating new artworks or music, creating realistic photos of humans that have never existed or augmenting real images for virtual reality applications. Since GANs are capable of generating realistic data sets they can also be used in conjunction with other discriminative machine learning models to create larger data samples and facilitate training of discriminative models. \n",
        "\n",
        "<br>There are a number of ways in which the GAN framework proposed by Goodfellow et al. could be extended. For example, the ratio of training iterations for the discriminative network (‘*k*’) vs. the generative network is determined arbitrarily in the Goodfellow et al. paper. Research could be conducted into the optimal setting of k such that trade-off between GAN performance vs. training time is optimised. As suggested by Goodfellow et al., research into conditional generative models is another interesting extension. Conditional GANs would enable users to guide the output from the generative model based on desired targets and further increase the application of GANs. Another intuitive extension to GAN research is the use of the GAN framework with alternate machine learning models (e.g. generative and discriminative models that are not multilayer perceptrons).\n",
        "\n",
        "<br>Presented below are two visual examples of variations to the GAN framework implemented in subsequent research papers.</justify>\n",
        "\n",
        "<br><center>**Image Filling**\n",
        "<br><img src=\"https://github.com/11223548/UTS_ML2019_Main/blob/master/GAN-Image%20Filling.jpg?raw=true\" width=\"800\"/>\n",
        "<br>Source: Context Encoders: Feature Learning by Inpainting, 2016</center>\n",
        "\n",
        "<br><justify>In a 2016 paper titled “Context Encoders: Feature Learning by Inpainting” the authors use a specific form of GANs, called context encoders, to generate images to fill in missing sections of a photo.</justify>\n",
        "\n",
        "<br><center>**Human Face Generation**\n",
        "<br><img src=\"https://github.com/11223548/UTS_ML2019_Main/blob/master/GAN-Face%20Generation.jpg?raw=true\" width=\"800\"/>\n",
        "<br>Source: Progressive Growing of GANs for Improved Quality, Stability, and Variation, 2017</center>\n",
        "\n",
        "<br><justify>In a 2017 paper titled “Progressive Growing of GANs for Improved Quality, Stability, and Variation” the authors use a GAN to generate highly realistic images of human faces.\n",
        "\n",
        "<br>One significant downside to GANs, and subsequent advances in generative modelling, is that they can be used for nefarious applications. For example, cutting-edge GANs have the potential to be used to generate fake pornography videos of celebrities or counterfeit videos of innocent people committing criminal activities. As a result, some nations have already begun to implement laws regarding the manner in which generative models can be used. The benefits and costs of wider adoption of GANs makes for an interesting discussion that will garner increasing public attention over the next decade.\n",
        "</justify>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3kXPTZhx1KS",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yieK2q9Lx1KT",
        "colab_type": "text"
      },
      "source": [
        "<justify>The Goodfellow et al. paper is of a high quality and exhibits a clear and intuitive structure that facilitated my personal reading and understanding of GANs. The authors provide context as to the importance of the new machine learning framework and its contribution to existing research. Whilst the framework introduced can be applied to various model types, a clear example (multilayer perceptrons) is focused upon by the authors to reinforce the process by which the generative model and discriminative model interact. Given the importance of the adversarial approach as a key innovation, the authors supplement the formal explanation of the model optimisation process with a layman’s explanation (see Figure 1 of the Goodfellow et al. paper) which makes the paper more accessible to readers that lack a formal academic background. Important theoretical properties of the GAN are provided alongside their formal derivations which makes it clear to readers how the authors arrived at their propositions. The authors also present some experimental applications of GANs. However, this section of the paper is very light on quantification of performance. Finally, the authors explain their view of the key advantages and disadvantages of GANs and provide a concise list of future extensions to the GAN framework.\n",
        "\n",
        "<br>The main criticism with respect to the presentation of the paper is that the authors could have made the case for adoption of GANs more compelling by including more statistics on the comparative performance of GANs against alternate generative models for the experiment data tested. Instead, the authors shied away from attempting to quantify outperformance and state that they “*make no claim that these samples are better than samples generated by existing methods*” (Goodfellow et al. 2014, p. 6).</justify>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtF4CPGVx1KU",
        "colab_type": "text"
      },
      "source": [
        "## References\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUXWcV6xRze8",
        "colab_type": "text"
      },
      "source": [
        "<br>[1] Brownlee, J. 2019,‘18 Impressive Applications of Generative Adversarial Networks (GANs)’, *Machine Learning Mastery*, weblog, 14 June, viewed 27 August 2019, <https://machinelearningmastery.com/impressive-applications-of-generative-adversarial-networks/>.\n",
        "\n",
        "<br>[2] Brownlee, J. 2019,‘A Gentle Introduction to Generative Adversarial Networks (GANs)’, *Machine Learning Mastery*, weblog, 17 June, viewed 27 August 2019, <https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/>.\n",
        "\n",
        "<br>[3] Dabir, S. 2017,‘Why training a Generative Adversarial Network (GAN) Model is no piece of cake’, *Packt*, weblog, 14 December, viewed 28 August 2019, <https://hub.packtpub.com/challenges-training-gans-generative-adversarial-networks/>.\n",
        "\n",
        "<br>[4] Goodfellow, I., Pouget-Abadie, J., Mehdi, M., Bing, X., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., 2014, ‘Generative Adversarial Nets’, *Advances in Neural Information Processing Systems*, vol. 27.\n",
        "\n",
        "<br>[5] Hui, J. 2018, ‘GAN — A comprehensive review into the gangsters of GANs’, *Medium*, weblog, 28 June, viewed 23 August 2019, <https://medium.com/@jonathan_hui/gan-a-comprehensive-review-into-the-gangsters-of-gans-part-1-95ff52455672>.\n",
        "\n",
        "<br>[6] Hui, J. 2018, ‘GAN – Some Cool Applications of GANs.’, *Medium*, weblog, 23 June, viewed 23 August 2019, <https://medium.com/@jonathan_hui/gan-some-cool-applications-of-gans-4c9ecca35900>.\n",
        "\n",
        "<br>[7] Hui, J. 2018, ‘GAN – What is Generative Adversary Networks GAN?’, *Medium*, weblog, 20 June, viewed 23 August 2019, <https://medium.com/@jonathan_hui/gan-whats-generative-adversarial-networks-and-its-application-f39ed278ef09>.\n",
        "\n",
        "<br>[8] Karazeev, A. 2017, ‘Generative Adversarial Networks (GANs): Engine and Applications’, *Cube.js*, weblog, 17 August, viewed 23 August 2019, <https://cube.dev/blog/generative-adversarial-networks-gans-engine-and-applications/>.\n",
        "\n",
        "<br>[9] Siminoni, T. 2018, ‘How AI can learn to generate pictures of cats’, *Freecodecamp*, weblog, 19 March, viewed 28 August 2019, <https://www.freecodecamp.org/news/how-ai-can-learn-to-generate-pictures-of-cats-ba692cb6eae4/>.\n",
        "\n",
        "<br>[10] Shorten, C. 2019, ‘Must-Read Papers on GANs’, *Towards Data Science*, weblog, 5 March, viewed 23 August 2019, <https://towardsdatascience.com/must-read-papers-on-gans-b665bbae3317>.\n",
        "\n",
        "<br>[11] Yakovenko, N. 2017, ‘GANs will change the world’, *Medium*, weblog, 4 Jan, viewed 27 August 2019, <https://medium.com/@Moscow25/gans-will-change-the-world-7ed6ae8515ca>.\n"
      ]
    }
  ]
}